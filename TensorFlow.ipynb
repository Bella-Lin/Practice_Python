{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 測試是否安裝成功"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "from pprint import pprint\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\envs\\myenv\\python.exe\n",
      "3.5.5 |Anaconda, Inc.| (default, Apr  7 2018, 04:52:34) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "print(sys.executable)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 運算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(1)\n",
    "b = tf.constant(2)\n",
    "c = a*b\n",
    "sess = tf.Session() \n",
    "result= sess.run(c)\n",
    "pprint(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Session in module tensorflow.python.client.session object:\n",
      "\n",
      "class Session(BaseSession)\n",
      " |  A class for running TensorFlow operations.\n",
      " |  \n",
      " |  A `Session` object encapsulates the environment in which `Operation`\n",
      " |  objects are executed, and `Tensor` objects are evaluated. For\n",
      " |  example:\n",
      " |  \n",
      " |  ```python\n",
      " |  # Build a graph.\n",
      " |  a = tf.constant(5.0)\n",
      " |  b = tf.constant(6.0)\n",
      " |  c = a * b\n",
      " |  \n",
      " |  # Launch the graph in a session.\n",
      " |  sess = tf.Session()\n",
      " |  \n",
      " |  # Evaluate the tensor `c`.\n",
      " |  print(sess.run(c))\n",
      " |  ```\n",
      " |  \n",
      " |  A session may own resources, such as\n",
      " |  @{tf.Variable}, @{tf.QueueBase},\n",
      " |  and @{tf.ReaderBase}. It is important to release\n",
      " |  these resources when they are no longer required. To do this, either\n",
      " |  invoke the @{tf.Session.close} method on the session, or use\n",
      " |  the session as a context manager. The following two examples are\n",
      " |  equivalent:\n",
      " |  \n",
      " |  ```python\n",
      " |  # Using the `close()` method.\n",
      " |  sess = tf.Session()\n",
      " |  sess.run(...)\n",
      " |  sess.close()\n",
      " |  \n",
      " |  # Using the context manager.\n",
      " |  with tf.Session() as sess:\n",
      " |    sess.run(...)\n",
      " |  ```\n",
      " |  \n",
      " |  The\n",
      " |  [`ConfigProto`](https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto)\n",
      " |  protocol buffer exposes various configuration options for a\n",
      " |  session. For example, to create a session that uses soft constraints\n",
      " |  for device placement, and log the resulting placement decisions,\n",
      " |  create a session as follows:\n",
      " |  \n",
      " |  ```python\n",
      " |  # Launch the graph in a session that allows soft device placement and\n",
      " |  # logs the placement decisions.\n",
      " |  sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
      " |                                          log_device_placement=True))\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Session\n",
      " |      BaseSession\n",
      " |      SessionInterface\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |  \n",
      " |  __exit__(self, exec_type, exec_value, exec_tb)\n",
      " |  \n",
      " |  __init__(self, target='', graph=None, config=None)\n",
      " |      Creates a new TensorFlow session.\n",
      " |      \n",
      " |      If no `graph` argument is specified when constructing the session,\n",
      " |      the default graph will be launched in the session. If you are\n",
      " |      using more than one graph (created with `tf.Graph()` in the same\n",
      " |      process, you will have to use different sessions for each graph,\n",
      " |      but each graph can be used in multiple sessions. In this case, it\n",
      " |      is often clearer to pass the graph to be launched explicitly to\n",
      " |      the session constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |        target: (Optional.) The execution engine to connect to.\n",
      " |          Defaults to using an in-process engine. See\n",
      " |          @{$distributed$Distributed TensorFlow}\n",
      " |          for more examples.\n",
      " |        graph: (Optional.) The `Graph` to be launched (described above).\n",
      " |        config: (Optional.) A\n",
      " |          [`ConfigProto`](https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto)\n",
      " |          protocol buffer with configuration options for the session.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  reset(target, containers=None, config=None)\n",
      " |      Resets resource containers on `target`, and close all connected sessions.\n",
      " |      \n",
      " |      A resource container is distributed across all workers in the\n",
      " |      same cluster as `target`.  When a resource container on `target`\n",
      " |      is reset, resources associated with that container will be cleared.\n",
      " |      In particular, all Variables in the container will become undefined:\n",
      " |      they lose their values and shapes.\n",
      " |      \n",
      " |      NOTE:\n",
      " |      (i) reset() is currently only implemented for distributed sessions.\n",
      " |      (ii) Any sessions on the master named by `target` will be closed.\n",
      " |      \n",
      " |      If no resource containers are provided, all containers are reset.\n",
      " |      \n",
      " |      Args:\n",
      " |        target: The execution engine to connect to.\n",
      " |        containers: A list of resource container name strings, or `None` if all of\n",
      " |          all the containers are to be reset.\n",
      " |        config: (Optional.) Protocol buffer with configuration options.\n",
      " |      \n",
      " |      Raises:\n",
      " |        tf.errors.OpError: Or one of its subclasses if an error occurs while\n",
      " |          resetting containers.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSession:\n",
      " |  \n",
      " |  __del__(self)\n",
      " |  \n",
      " |  as_default(self)\n",
      " |      Returns a context manager that makes this object the default session.\n",
      " |      \n",
      " |      Use with the `with` keyword to specify that calls to\n",
      " |      @{tf.Operation.run} or @{tf.Tensor.eval} should be executed in\n",
      " |      this session.\n",
      " |      \n",
      " |      ```python\n",
      " |      c = tf.constant(..)\n",
      " |      sess = tf.Session()\n",
      " |      \n",
      " |      with sess.as_default():\n",
      " |        assert tf.get_default_session() is sess\n",
      " |        print(c.eval())\n",
      " |      ```\n",
      " |      \n",
      " |      To get the current default session, use @{tf.get_default_session}.\n",
      " |      \n",
      " |      *N.B.* The `as_default` context manager *does not* close the\n",
      " |      session when you exit the context, and you must close the session\n",
      " |      explicitly.\n",
      " |      \n",
      " |      ```python\n",
      " |      c = tf.constant(...)\n",
      " |      sess = tf.Session()\n",
      " |      with sess.as_default():\n",
      " |        print(c.eval())\n",
      " |      # ...\n",
      " |      with sess.as_default():\n",
      " |        print(c.eval())\n",
      " |      \n",
      " |      sess.close()\n",
      " |      ```\n",
      " |      \n",
      " |      Alternatively, you can use `with tf.Session():` to create a\n",
      " |      session that is automatically closed on exiting the context,\n",
      " |      including when an uncaught exception is raised.\n",
      " |      \n",
      " |      *N.B.* The default session is a property of the current thread. If you\n",
      " |      create a new thread, and wish to use the default session in that\n",
      " |      thread, you must explicitly add a `with sess.as_default():` in that\n",
      " |      thread's function.\n",
      " |      \n",
      " |      *N.B.* Entering a `with sess.as_default():` block does not affect\n",
      " |      the current default graph. If you are using multiple graphs, and\n",
      " |      `sess.graph` is different from the value of @{tf.get_default_graph},\n",
      " |      you must explicitly enter a `with sess.graph.as_default():` block\n",
      " |      to make `sess.graph` the default graph.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A context manager using this session as the default session.\n",
      " |  \n",
      " |  close(self)\n",
      " |      Closes this session.\n",
      " |      \n",
      " |      Calling this method frees all resources associated with the session.\n",
      " |      \n",
      " |      Raises:\n",
      " |        tf.errors.OpError: Or one of its subclasses if an error occurs while\n",
      " |          closing the TensorFlow session.\n",
      " |  \n",
      " |  list_devices(self)\n",
      " |      Lists available devices in this session.\n",
      " |      \n",
      " |      ```python\n",
      " |      devices = sess.list_devices()\n",
      " |      for d in devices:\n",
      " |        print(d.name)\n",
      " |      ```\n",
      " |      \n",
      " |      Each element in the list has the following properties:\n",
      " |       - `name`: A string with the full name of the device. ex:\n",
      " |            `/job:worker/replica:0/task:3/device:CPU:0`\n",
      " |       - `device_type`: The type of the device (e.g. `CPU`, `GPU`, `TPU`.)\n",
      " |       - `memory_limit`: The maximum amount of memory available on the device.\n",
      " |            Note: depending on the device, it is possible the usable memory could\n",
      " |            be substantially less.\n",
      " |      Raises:\n",
      " |        tf.errors.OpError: If it encounters an error (e.g. session is in an\n",
      " |        invalid state, or network errors occur).\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of devices in the session.\n",
      " |  \n",
      " |  make_callable(self, fetches, feed_list=None, accept_options=False)\n",
      " |      Returns a Python callable that runs a particular step.\n",
      " |      \n",
      " |      The returned callable will take `len(feed_list)` arguments whose types\n",
      " |      must be compatible feed values for the respective elements of `feed_list`.\n",
      " |      For example, if element `i` of `feed_list` is a `tf.Tensor`, the `i`th\n",
      " |      argument to the returned callable must be a numpy ndarray (or something\n",
      " |      convertible to an ndarray) with matching element type and shape. See\n",
      " |      @{tf.Session.run} for details of the allowable feed key and value types.\n",
      " |      \n",
      " |      The returned callable will have the same return type as\n",
      " |      `tf.Session.run(fetches, ...)`. For example, if `fetches` is a `tf.Tensor`,\n",
      " |      the callable will return a numpy ndarray; if `fetches` is a `tf.Operation`,\n",
      " |      it will return `None`.\n",
      " |      \n",
      " |      Args:\n",
      " |        fetches: A value or list of values to fetch. See @{tf.Session.run}\n",
      " |          for details of the allowable fetch types.\n",
      " |        feed_list: (Optional.) A list of `feed_dict` keys. See\n",
      " |          @{tf.Session.run} for details of the allowable feed key types.\n",
      " |        accept_options: (Optional.) Iff `True`, the returned `Callable` will be\n",
      " |          able to accept @{tf.RunOptions} and @{tf.RunMetadata} as optional\n",
      " |          keyword arguments `options` and `run_metadata`, respectively, with\n",
      " |          the same syntax and semantics as @{tf.Session.run}, which is useful\n",
      " |          for certain use cases (profiling and debugging) but will result in\n",
      " |          measurable slowdown of the `Callable`'s performance. Default: `False`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A function that when called will execute the step defined by\n",
      " |        `feed_list` and `fetches` in this session.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If `fetches` or `feed_list` cannot be interpreted\n",
      " |          as arguments to @{tf.Session.run}.\n",
      " |  \n",
      " |  partial_run(self, handle, fetches, feed_dict=None)\n",
      " |      Continues the execution with more feeds and fetches.\n",
      " |      \n",
      " |      This is EXPERIMENTAL and subject to change.\n",
      " |      \n",
      " |      To use partial execution, a user first calls `partial_run_setup()` and\n",
      " |      then a sequence of `partial_run()`. `partial_run_setup` specifies the\n",
      " |      list of feeds and fetches that will be used in the subsequent\n",
      " |      `partial_run` calls.\n",
      " |      \n",
      " |      The optional `feed_dict` argument allows the caller to override\n",
      " |      the value of tensors in the graph. See run() for more information.\n",
      " |      \n",
      " |      Below is a simple example:\n",
      " |      \n",
      " |      ```python\n",
      " |      a = array_ops.placeholder(dtypes.float32, shape=[])\n",
      " |      b = array_ops.placeholder(dtypes.float32, shape=[])\n",
      " |      c = array_ops.placeholder(dtypes.float32, shape=[])\n",
      " |      r1 = math_ops.add(a, b)\n",
      " |      r2 = math_ops.multiply(r1, c)\n",
      " |      \n",
      " |      h = sess.partial_run_setup([r1, r2], [a, b, c])\n",
      " |      res = sess.partial_run(h, r1, feed_dict={a: 1, b: 2})\n",
      " |      res = sess.partial_run(h, r2, feed_dict={c: res})\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        handle: A handle for a sequence of partial runs.\n",
      " |        fetches: A single graph element, a list of graph elements,\n",
      " |          or a dictionary whose values are graph elements or lists of graph\n",
      " |          elements (see documentation for `run`).\n",
      " |        feed_dict: A dictionary that maps graph elements to values\n",
      " |          (described above).\n",
      " |      \n",
      " |      Returns:\n",
      " |        Either a single value if `fetches` is a single graph element, or\n",
      " |        a list of values if `fetches` is a list, or a dictionary with the\n",
      " |        same keys as `fetches` if that is a dictionary\n",
      " |        (see documentation for `run`).\n",
      " |      \n",
      " |      Raises:\n",
      " |        tf.errors.OpError: Or one of its subclasses on error.\n",
      " |  \n",
      " |  partial_run_setup(self, fetches, feeds=None)\n",
      " |      Sets up a graph with feeds and fetches for partial run.\n",
      " |      \n",
      " |      This is EXPERIMENTAL and subject to change.\n",
      " |      \n",
      " |      Note that contrary to `run`, `feeds` only specifies the graph elements.\n",
      " |      The tensors will be supplied by the subsequent `partial_run` calls.\n",
      " |      \n",
      " |      Args:\n",
      " |        fetches: A single graph element, or a list of graph elements.\n",
      " |        feeds: A single graph element, or a list of graph elements.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A handle for partial run.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If this `Session` is in an invalid state (e.g. has been\n",
      " |          closed).\n",
      " |        TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.\n",
      " |        tf.errors.OpError: Or one of its subclasses if a TensorFlow error happens.\n",
      " |  \n",
      " |  run(self, fetches, feed_dict=None, options=None, run_metadata=None)\n",
      " |      Runs operations and evaluates tensors in `fetches`.\n",
      " |      \n",
      " |      This method runs one \"step\" of TensorFlow computation, by\n",
      " |      running the necessary graph fragment to execute every `Operation`\n",
      " |      and evaluate every `Tensor` in `fetches`, substituting the values in\n",
      " |      `feed_dict` for the corresponding input values.\n",
      " |      \n",
      " |      The `fetches` argument may be a single graph element, or an arbitrarily\n",
      " |      nested list, tuple, namedtuple, dict, or OrderedDict containing graph\n",
      " |      elements at its leaves.  A graph element can be one of the following types:\n",
      " |      \n",
      " |      * An @{tf.Operation}.\n",
      " |        The corresponding fetched value will be `None`.\n",
      " |      * A @{tf.Tensor}.\n",
      " |        The corresponding fetched value will be a numpy ndarray containing the\n",
      " |        value of that tensor.\n",
      " |      * A @{tf.SparseTensor}.\n",
      " |        The corresponding fetched value will be a\n",
      " |        @{tf.SparseTensorValue}\n",
      " |        containing the value of that sparse tensor.\n",
      " |      * A `get_tensor_handle` op.  The corresponding fetched value will be a\n",
      " |        numpy ndarray containing the handle of that tensor.\n",
      " |      * A `string` which is the name of a tensor or operation in the graph.\n",
      " |      \n",
      " |      The value returned by `run()` has the same shape as the `fetches` argument,\n",
      " |      where the leaves are replaced by the corresponding values returned by\n",
      " |      TensorFlow.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |         a = tf.constant([10, 20])\n",
      " |         b = tf.constant([1.0, 2.0])\n",
      " |         # 'fetches' can be a singleton\n",
      " |         v = session.run(a)\n",
      " |         # v is the numpy array [10, 20]\n",
      " |         # 'fetches' can be a list.\n",
      " |         v = session.run([a, b])\n",
      " |         # v is a Python list with 2 numpy arrays: the 1-D array [10, 20] and the\n",
      " |         # 1-D array [1.0, 2.0]\n",
      " |         # 'fetches' can be arbitrary lists, tuples, namedtuple, dicts:\n",
      " |         MyData = collections.namedtuple('MyData', ['a', 'b'])\n",
      " |         v = session.run({'k1': MyData(a, b), 'k2': [b, a]})\n",
      " |         # v is a dict with\n",
      " |         # v['k1'] is a MyData namedtuple with 'a' (the numpy array [10, 20]) and\n",
      " |         # 'b' (the numpy array [1.0, 2.0])\n",
      " |         # v['k2'] is a list with the numpy array [1.0, 2.0] and the numpy array\n",
      " |         # [10, 20].\n",
      " |      ```\n",
      " |      \n",
      " |      The optional `feed_dict` argument allows the caller to override\n",
      " |      the value of tensors in the graph. Each key in `feed_dict` can be\n",
      " |      one of the following types:\n",
      " |      \n",
      " |      * If the key is a @{tf.Tensor}, the\n",
      " |        value may be a Python scalar, string, list, or numpy ndarray\n",
      " |        that can be converted to the same `dtype` as that\n",
      " |        tensor. Additionally, if the key is a\n",
      " |        @{tf.placeholder}, the shape of\n",
      " |        the value will be checked for compatibility with the placeholder.\n",
      " |      * If the key is a\n",
      " |        @{tf.SparseTensor},\n",
      " |        the value should be a\n",
      " |        @{tf.SparseTensorValue}.\n",
      " |      * If the key is a nested tuple of `Tensor`s or `SparseTensor`s, the value\n",
      " |        should be a nested tuple with the same structure that maps to their\n",
      " |        corresponding values as above.\n",
      " |      \n",
      " |      Each value in `feed_dict` must be convertible to a numpy array of the dtype\n",
      " |      of the corresponding key.\n",
      " |      \n",
      " |      The optional `options` argument expects a [`RunOptions`] proto. The options\n",
      " |      allow controlling the behavior of this particular step (e.g. turning tracing\n",
      " |      on).\n",
      " |      \n",
      " |      The optional `run_metadata` argument expects a [`RunMetadata`] proto. When\n",
      " |      appropriate, the non-Tensor output of this step will be collected there. For\n",
      " |      example, when users turn on tracing in `options`, the profiled info will be\n",
      " |      collected into this argument and passed back.\n",
      " |      \n",
      " |      Args:\n",
      " |        fetches: A single graph element, a list of graph elements,\n",
      " |          or a dictionary whose values are graph elements or lists of graph\n",
      " |          elements (described above).\n",
      " |        feed_dict: A dictionary that maps graph elements to values\n",
      " |          (described above).\n",
      " |        options: A [`RunOptions`] protocol buffer\n",
      " |        run_metadata: A [`RunMetadata`] protocol buffer\n",
      " |      \n",
      " |      Returns:\n",
      " |        Either a single value if `fetches` is a single graph element, or\n",
      " |        a list of values if `fetches` is a list, or a dictionary with the\n",
      " |        same keys as `fetches` if that is a dictionary (described above).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If this `Session` is in an invalid state (e.g. has been\n",
      " |          closed).\n",
      " |        TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.\n",
      " |        ValueError: If `fetches` or `feed_dict` keys are invalid or refer to a\n",
      " |          `Tensor` that doesn't exist.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseSession:\n",
      " |  \n",
      " |  graph\n",
      " |      The graph that was launched in this session.\n",
      " |  \n",
      " |  graph_def\n",
      " |      A serializable version of the underlying TensorFlow graph.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A graph_pb2.GraphDef proto containing nodes for all of the Operations in\n",
      " |        the underlying TensorFlow graph.\n",
      " |  \n",
      " |  sess_str\n",
      " |      The TensorFlow process to which this session will connect.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from SessionInterface:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(help(sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[1., 2.],\n",
      "       [0., 4.]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from pprint import pprint\n",
    "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "d = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
    "e = c*d\n",
    "sess = tf.Session() \n",
    "result= sess.run(e)\n",
    "pprint(sess.run(e))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 58,  64],\n",
      "       [139, 154]])\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
    "b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
    "c = tf.matmul(a, b) \n",
    "sess = tf.Session() \n",
    "result= sess.run(c)\n",
    "pprint(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable a is 9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# first, create a TensorFlow constant\n",
    "const = tf.constant(2.0, name=\"const\")\n",
    "    \n",
    "# create TensorFlow variables\n",
    "b1 = tf.Variable(2.0, name='var')\n",
    "c1 = tf.Variable(1.0, name='var')\n",
    "\n",
    "# now create some operations\n",
    "d1 = tf.add(b1, c1, name='op_d')\n",
    "e1 = tf.add(c1, const, name='op_e')\n",
    "f = tf.multiply(d1, e1, name='final_f')\n",
    "# setup the variable initialisation\n",
    "init_op = tf.global_variables_initializer()\n",
    "# start the session\n",
    "sess = tf.Session() \n",
    "sess.run(init_op)\n",
    "output_f = sess.run(f)\n",
    "\n",
    "print(\"Variable a is {}\".format(output_f))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable可變化性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 活化函數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import tensorflow as tf\n",
    "tf.summary.FileWriterCache.clear()\n",
    "a = tf.constant( 1,name = 'a')\n",
    "b = tf.constant(2,name = 'b')\n",
    "c = tf.constant(3,name = 'c')\n",
    "d = tf.constant(4,name = 'd')\n",
    "\n",
    "add1 = tf.add(a, b,name = 'add1')\n",
    "mul1 = tf.multiply(b, c,name = 'mul1')\n",
    "#add2 = tf.add(c, d,name = 'add2')\n",
    "output = tf.add(add1, mul1,name = 'output')\n",
    "\n",
    "sess = tf.Session() \n",
    "print_result = sess.run(output)\n",
    "print (print_result)\n",
    "    \n",
    "tf.summary.merge_all()\n",
    "#將tensorBoard資料寫入地點\n",
    "tf.summary.FileWriter('C:\\\\Users\\\\USER\\\\Anaconda3\\\\envs\\\\myenv\\\\log\\\\area',sess.graph)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
